---
title: "algal_bloom"
author: "Tarrik Quneibi"
date: "2022-11-14"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(readr)
library(rvest)
library(plotly)
library(ggplot2)
library(lubridate)
library(Amelia)
library(tidyverse)
library(Hmisc)
library(neuralnet)
library("keras")
library(tensorflow)
library(reticulate)	
```
```{r python}
py_path = "C:\\Users\\Tarri\\anaconda3\\" 
use_python(py_path, required = T)	
```


```{r}

# url3 <- "https://seagull-erddap.glos.org/erddap/tabledap/obs_117.htmlTable?time%2Clongitude%2Clatitude%2Cnitrate&time%3E=2021-01-01T00%3A00%3A00Z&time%3C=2022-11-01T00%3A00%3A00Z"
# 
# wiki_url3 <- read_html(url3) # UCLA SOCR Data
# df3 <- as.data.frame(html_table(html_nodes(wiki_url3, "table")[[2]]))
# 
# df3 <- df3[-1 , ]
# 
# time <- df3$time
# df3 <- subset(df3, select=-c(time))
# df3 <- as.data.frame(sapply(df3, as.numeric))
# df3 <- cbind(time, df3)
# df3$time <- ymd_hms(df3$time )
# 
# obs_data_3 <- df3[complete.cases(df3), ] %>%
#   select(c("time","nitrate"))
# 
# 
# 
# 
# url4 <-"https://seagull-erddap.glos.org/erddap/tabledap/obs_22.htmlTable?time%2Clongitude%2Clatitude%2Cchlorophyll_fluorescence%2Cfractional_saturation_of_oxygen_in_sea_water%2Cmass_concentration_of_blue_green_algae_in_sea_water%2Cmass_concentration_of_blue_green_algae_in_sea_water_rfu%2Cmass_concentration_of_chlorophyll_in_sea_water%2Cmass_concentration_of_oxygen_in_sea_water%2Csea_surface_temperature%2Csea_water_electrical_conductivity%2Csea_water_ph_reported_on_total_scale&time%3E=2022-07-25T00%3A00%3A00Z&time%3C=2022-11-01T00%3A00%3A00Z"
# wiki_url4 <- read_html(url4) # UCLA SOCR Data
# df4 <- as.data.frame(html_table(html_nodes(wiki_url4, "table")[[2]]))
# 
# df4 <- df4[-1 , ]
# 
# time <- df4$time
# df4 <- subset(df4, select=-c(time))
# df4 <- as.data.frame(sapply(df4, as.numeric))
# df4 <- cbind(time, df4)
# df4$time <- ymd_hms(df4$time )
# 
# obs_data <- inner_join(df4, obs_data_3, by='time')
# 
# url5 <- "https://seagull-erddap.glos.org/erddap/tabledap/obs_121.htmlTable?time%2Cammonia%2Cphosphate&time%3E=2022-07-25T00%3A00%3A00Z&time%3C=2022-11-01T00%3A00%3A00Z&phosphate!=NaN"
# wiki_url5 <- read_html(url5) # UCLA SOCR Data
# df5 <- as.data.frame(html_table(html_nodes(wiki_url5, "table")[[2]]))
# 
# df5 <- df5[-1 , ]
# 
# time <- df5$time
# df5 <- subset(df5, select=-c(time))
# df5 <- as.data.frame(sapply(df5, as.numeric))
# df5 <- cbind(time, df5)
# df5$time <- ymd_hms(df5$time )
# df5$ammonia <- abs(df5$ammonia)
# df5$phosphate <- abs(df5$phosphate)
# df5$time <- round_date(df5$time, "10 minutes")
# 
# obs_data <- inner_join(algae_data, df5, by='time')
```

```{r data save}
#write.csv(obs_data, "C:\\Users\\Tarri\\Desktop\\portfolio_projects\\algal_bloom_dashboard\\data\\algae_data.csv")



```

```{r read in data}
algae_data <- read_csv("C:\\Users\\Tarri\\Desktop\\portfolio_projects\\algal_bloom_dashboard\\data\\algae_data.csv")


```

```{r summary data}
summary(algae_data)


```



# Missing Data
From the missingness map, we can see that there is very little missing data, and it appears to only be from the ammonia column. Since a very small portion of data is missing, the rows with missing data were removed.

```{r missing data}
missmap(algae_data)
algae_data <- algae_data[complete.cases(algae_data), ]

```

```{r data sub}
algae_sub <- algae_data %>%
  select(-c("...1","...2","time","latitude","longitude"))
headers <- c("chlorophyll_flourescence_(rfu)","oxygen_saturation_(fraction)","bluegreen_algae_conc_(ug/L)",
             "bluegreen_algae_conc_(rfu)","chlorophyll_conc_(kg/m3)","oxygen_conc_(kg/m3)","temp_(K)","elec_cond_(s/m)",
             "pH","nitrate_(ug/L)","ammonia_(ug/L)","phosphate_(ug/L)")
names(algae_sub) <- headers
algae_sub <- as.data.frame(sapply(algae_sub, abs))

```


```{r correlation}

rcorr(as.matrix(algae_sub, method="Spearman"))


```

```{r pairs plot}
set.seed(42)

dims <- dplyr::select_if(algae_sub, is.numeric)
dims <- purrr::map2(dims, names(dims), ~list(values=.x, label=.y))
plot_ly(type = "splom", dimensions = setNames(dims, NULL), showupperhalf = FALSE, 
        diagonal = list(visible = FALSE) ,textangle = 45) %>% 
  layout( title='<b> Lake Erie water parameter Pairs-Plots </b>')

```

# Neural Network

```{r pre processing}
set.seed(55)
algae_nn <- algae_sub %>%
  select(-c('bluegreen_algae_conc_(rfu)'))

normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}

algae_norm<-as.data.frame(lapply(algae_nn, normalize))


sub <- sample(nrow(algae_norm), floor(nrow(algae_norm)*0.80))
algae_train <- algae_norm[sub, ]
algae_test <- algae_norm[-sub, ]


```

```{r nn}
set.seed(55)
algae_model <- neuralnet(~bluegreen_algae_conc_.ug.L.~., data=algae_norm, hidden= c(6 , 4), learningrate = 0.01)
plot(algae_model)


```

```{r model accuracy}
set.seed(55)
algae_pred <- compute(algae_model, algae_test[, c(1:2, 4:11)])
pred_results <- algae_pred$net.result
cor(pred_results, algae_test$bluegreen_algae_conc_.ug.L.)

algae_df <- data.frame(actual = algae_test$bluegreen_algae_conc_.ug.L., predicted = pred_results)
```


```{r plotting}
set.seed(42)
plot_ly() %>%
  add_markers(x=pred_results, y=algae_test$bluegreen_algae_conc_.ug.L., 
              name="Data Scatter", type="scatter", mode="markers") %>%
  add_trace(x = c(0,1), y = c(0,1), type="scatter", mode="lines",
        line = list(width = 4), name="Ideal Agreement") %>%
  layout(title=paste0('Scatterplot (Normalized) Observed vs. Predicted Values, Cor(Obs,Pred)=',
                      round(cor(pred_results, algae_test$bluegreen_algae_conc_.ug.L.), 2)),
           xaxis = list(title="NN (hidden=4) Predictions"),
           yaxis = list(title="(Normalized) Observed"),
           legend = list(orientation = 'h'))
```

```{r classifier}
set.seed(42)
algae_class <- algae_norm

headers <- c("chlorophyll_flourescence_(rfu)","oxygen_saturation_(fraction)","bluegreen_algae_conc_(ug/L)",
             "chlorophyll_conc_(kg/m3)","oxygen_conc_(kg/m3)","temp_(K)","elec_cond_(s/m)",
             "pH","nitrate_(ug/L)","ammonia_(ug/L)","phosphate_(ug/L)")
names(algae_class) <- headers

id1 = which(algae_class$`bluegreen_algae_conc_(ug/L)` < 0.1)
id2 = which(algae_class$`bluegreen_algae_conc_(ug/L)` > 0.2)
id3 = setdiff(1:nrow(algae_class),union(id1,id2))
algae_class$`bluegreen_algae_conc_(ug/L)`[id1]=0
algae_class$`bluegreen_algae_conc_(ug/L)`[id2]=2
algae_class$`bluegreen_algae_conc_(ug/L)`[id3]=1


summary(as.factor(algae_class$`bluegreen_algae_conc_(ug/L)`))


```

```{r classifier train and test}
set.seed(42)
train = sample(1:nrow(algae_class),0.75*nrow(algae_class))
algae_tr = algae_class[train,]
algae_ts = algae_class[-train,]
train_x = algae_tr[,c(1:2,4:11)]
train_y = algae_tr[,3]
colnames(train_x)

test_x = algae_ts[,c(1:2,4:8)]
test_y = algae_ts[3]
train_y_ind = model.matrix(~factor(train_y)-1)
colnames(train_y_ind) = c("Low","Median","High")
train = cbind(train_x, train_y_ind)
names(train) <- make.names(names(train))

```


```{r NN classifier}
set.seed(42)
nn_single = neuralnet(Low+Median+High~ .,
    data = train,
    hidden=10,#c(10,8,6),
    # linear.output=FALSE,
    # lifesign='full', lifesign.step=5000,
    threshold = 0.3)
```


```{r}
set.seed()
pred = function(nn, dat) {
    # compute uses the trained neural net (nn=nn_single), and 
    # new testing data (dat=google_ts) to generate predictions (y_hat)
    # compute returns a list containing: 
    #     (1) neurons: a list of the neurons' output for each layer of the neural network, and
    #     (2) net.result: a matrix containing the overall result of the neural network.
    yhat = compute(nn, dat)$net.result
    
    # find the maximum in each row (1) in the net.result matrix
    # to determine the first occurrence of a specific element in each row (1)
    # we can use the apply function with which.max
    yhat = apply(yhat, 1, which.max)-1
    return(yhat)
}

mean(pred(nn_single, algae_ts[,c(1:2,4:11)]) != as.factor(algae_ts[,3]))

table(pred(nn_single, algae_ts[,c(1:2,4:11)]), as.factor(algae_ts[,3]))

```

///////////////////////////////////////////////////////////////////////////////////

```{r deep learning}
dat2 <- as.matrix(algae_sub)
dimnames(dat2) <- NULL
dat2 <- dat2[ , c(1:2 ,5:12)]

# May be best to avoid normalizing the ordinal variable "ticketcount"
dat2.norm <- keras::normalize(dat2)

# headers <- c("chlorophyll_flourescence_(rfu)","oxygen_saturation_(fraction)","chlorophyll_conc_(kg/m3)","oxygen_conc_(kg/m3)","temp_(K)","elec_cond_(s/m)",
#              "pH","nitrate_(ug/L)","ammonia_(ug/L)","phosphate_(ug/L)")
# colnames(dat2.norm) <- headers





```


```{r }
set.seed(42)
train_set_ind <- sample(nrow(dat2.norm), floor(nrow(dat2.norm)*0.8)) # 80:20 plot training:testing
train_dat2.X <- dat2.norm[train_set_ind, ]
train_dat2.Y <- algae_sub$`bluegreen_algae_conc_(ug/L)`[train_set_ind]  # Outcome "algae concentration" column:3


test_dat2.X <- dat2.norm[-train_set_ind, ]
test_dat2.Y <- algae_sub$`bluegreen_algae_conc_(ug/L)`[-train_set_ind]  # Outcome "survived" column:8

# double check the size/dimensions of the training and testing data (predictors and responses)
dim(train_dat2.X); length(train_dat2.Y); dim(test_dat2.X); length(test_dat2.Y)


```


```{r NN }
model.1 <- keras_model_sequential() 

# Add layers to the model
model.1 %>% 
    layer_dense(units = 10, activation = 'relu', input_shape = c(10)) %>% 
    layer_dense(units = 2, activation = 'softmax')

model.1 %>% compile(
     loss = 'binary_crossentropy',
     optimizer = 'adam',
     metrics = 'accuracy'
 )

predictions <- predict(model.1, train_dat2.X)

predictions <- keras_predict(model.1,train_dat2.X , batch_size = 32, verbose = 1)
# track.model.1 <- model.1 %>% fit(
#      train_dat2.X, 
#      train_dat2.Y, 
#      epochs = 200, 
#      batch_size = 10, 
#      validation_split = 0.2
#  )


```
