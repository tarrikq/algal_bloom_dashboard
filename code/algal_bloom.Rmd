---
title: "algal_bloom"
author: "Tarrik Quneibi"
date: "2022-11-14"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(readr)
library(rvest)
library(plotly)
library(ggplot2)
library(lubridate)
library(Amelia)
library(tidyverse)
library(Hmisc)
library(neuralnet)
library("keras")
library(tensorflow)
library(reticulate)	
library(caret)
library(Boruta)
```
```{r python}
py_path = "C:\\Users\\Tarri\\anaconda3\\" 
use_python(py_path, required = T)	
```


```{r}

# url1 <-"https://seagull-erddap.glos.org/erddap/tabledap/obs_22.htmlTable?time%2Clongitude%2Clatitude%2Cchlorophyll_fluorescence%2Cfractional_saturation_of_oxygen_in_sea_water%2Cmass_concentration_of_blue_green_algae_in_sea_water%2Cmass_concentration_of_blue_green_algae_in_sea_water_rfu%2Cmass_concentration_of_chlorophyll_in_sea_water%2Cmass_concentration_of_oxygen_in_sea_water%2Csea_surface_temperature%2Csea_water_electrical_conductivity%2Csea_water_ph_reported_on_total_scale&time%3E=2022-07-25T00%3A00%3A00Z&time%3C=2022-11-01T00%3A00%3A00Z"
# wiki_url1 <- read_html(url1) # UCLA SOCR Data
# df1 <- as.data.frame(html_table(html_nodes(wiki_url1, "table")[[2]]))
# 
# df1 <- df1[-1 , ]
# 
# time <- df1$time
# df1 <- subset(df1, select=-c(time))
# df1 <- as.data.frame(sapply(df1, as.numeric))
# df1 <- cbind(time, df1)
# df1$time <- ymd_hms(df1$time )
# 
# url2 <- "https://seagull-erddap.glos.org/erddap/tabledap/obs_121.htmlTable?time%2Cammonia%2Cphosphate&time%3E=2022-07-25T00%3A00%3A00Z&time%3C=2022-11-01T00%3A00%3A00Z&phosphate!=NaN"
# wiki_url2 <- read_html(url2) # UCLA SOCR Data
# df2 <- as.data.frame(html_table(html_nodes(wiki_url2, "table")[[2]]))
# 
# df2 <- df2[-1 , ]
# 
# time <- df2$time
# df2 <- subset(df2, select=-c(time))
# df2 <- as.data.frame(sapply(df2, as.numeric))
# df2 <- cbind(time, df2)
# df2$time <- ymd_hms(df2$time )
# df2$time <- round_date(df2$time, "10 minutes")
# 
# obs_data <- inner_join(df1, df2, by='time')
# 
# url3 <- "https://seagull-erddap.glos.org/erddap/tabledap/obs_117.htmlTable?time%2Cphycocyanin_fluorescence&time%3E=2022-07-21T00%3A00%3A00Z&time%3C=2022-11-01T00%3A00%3A00Z"
# wiki_url3 <- read_html(url3) # UCLA SOCR Data
# df3 <- as.data.frame(html_table(html_nodes(wiki_url3, "table")[[2]]))
# 
# df3 <- df3[-1 , ]
# 
# time <- df3$time
# df3 <- subset(df3, select=-c(time))
# df3 <- as.data.frame(sapply(df3, as.numeric))
# df3 <- cbind(time, df3)
# df3$time <- ymd_hms(df3$time )
# 
# obs_data <- left_join(obs_data, df3, by='time')
# 
# url4 <- "https://seagull-erddap.glos.org/erddap/tabledap/obs_162.htmlTable?time%2Cnitrate&time%3E=2022-07-21T00%3A00%3A00Z"
# wiki_url4 <- read_html(url4) # UCLA SOCR Data
# df4 <- as.data.frame(html_table(html_nodes(wiki_url4, "table")[[2]]))
# 
# df4 <- df4[-1 , ]
# 
# time <- df4$time
# df4 <- subset(df4, select=-c(time))
# df4 <- as.data.frame(sapply(df4, as.numeric))
# df4 <- cbind(time, df4)
# df4$time <- ymd_hms(df4$time )
# 
# obs_data <- left_join(obs_data, df4, by='time')
```

```{r data save}
#write.csv(obs_data, "C:\\Users\\Tarri\\Desktop\\portfolio_projects\\algal_bloom_dashboard\\data\\algae_data.csv")



```

```{r read in data}
algae_data <- read_csv("C:\\Users\\Tarri\\Desktop\\portfolio_projects\\algal_bloom_dashboard\\data\\algae_data.csv")

```

```{r summary data}

```



# Missing Data
From the missingness map, we can see that there is very little missing data, and it appears to only be from the ammonia column. Since a very small portion of data is missing, the rows with missing data were removed.

```{r missing data}
algae_data[algae_data == 0] <- NA

missmap(algae_data)
#algae_data <- algae_data[complete.cases(algae_data), ]
```

```{r data sub}
algae_sub <- algae_data %>%
  select(-c("...1","time","latitude","longitude"))
headers <- c("chlorophyll_flourescence_rfu","oxygen_saturation_fraction","bluegreen_algae_conc_ug.L",
             "bluegreen_algae_conc_rfu","chlorophyll_conc_kg.m3","oxygen_conc_kg.m3","temp_K","elec_cond_s.m",
             "pH","ammonia_ug.L","phosphate_ug.L", "phycocayanin_flour_rfu","nitrate_ug.L")
names(algae_sub) <- headers
algae_sub <- as.data.frame(sapply(algae_sub, abs))

algae_data1 <- amelia(algae_sub, m=5)
algae_sub <- algae_data1$imputations$imp1
algae_sub <- as.data.frame(sapply(algae_sub, abs))

summary(algae_sub)

```


```{r correlation}

rcorr(as.matrix(algae_sub, method="Spearman"))


```

```{r pairs plot}
set.seed(42)

dims <- dplyr::select_if(algae_sub, is.numeric)
dims <- purrr::map2(dims, names(dims), ~list(values=.x, label=.y))
plot_ly(type = "splom", dimensions = setNames(dims, NULL), showupperhalf = FALSE, 
        diagonal = list(visible = FALSE) ,textangle = 45) %>% 
  layout( title='<b> Lake Erie water parameter Pairs-Plots </b>')

```

```{r boruta}
algae_bor <- algae_sub %>%
  select(-c('bluegreen_algae_conc_rfu'))

boruta <- Boruta(bluegreen_algae_conc_ug.L~.,data=algae_bor)

plot(boruta, xlab = "", xaxt = "n")
k <-lapply(1:ncol(boruta$ImpHistory),function(i)
  boruta$ImpHistory[is.finite(boruta$ImpHistory[,i]),i])
names(k) <- colnames(boruta$ImpHistory)
Labels <- sort(sapply(k,median))
axis(side = 1,las=2,labels = names(Labels),
       at = 1:ncol(boruta$ImpHistory), cex.axis = 0.7)


```


# Neural Network

```{r pre processing}
# algae_nn <- subset(algae_sub, bluegreen_algae_conc_ug.L < 3)

algae_nn <- algae_sub %>%
  select(-c('bluegreen_algae_conc_rfu'))



normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}

algae_norm<-as.data.frame(lapply(algae_nn, normalize))
set.seed(55)
sub <- sample(nrow(algae_norm), floor(nrow(algae_norm)*0.75))


# sub <- createDataPartition(algae_nn$`bluegreen_algae_conc_ug.L`, p = 0.75,
#                                    list = FALSE,
#                            times = 1)

algae_train <- algae_norm[sub, ] 
algae_test <- algae_norm[-sub, ]

#algae_train <- algae_train[order(algae_train$bluegreen_algae_conc_ug.L), ]


#algae_train_conc <- algae_train %>% select(c('bluegreen_algae_conc_ug.L'))
#algae_test_conc <-algae_test %>% select(c('bluegreen_algae_conc_ug.L'))
#algae_train <- algae_train %>% select(-c('bluegreen_algae_conc_ug.L'))
#algae_test <-algae_test %>% select(-c('bluegreen_algae_conc_ug.L'))

# algae_train_norm <- keras::normalize(algae_train)
# algae_test_norm <- keras::normalize(algae_test)

# algae_train <- cbind(algae_train_conc, algae_train_norm)
# algae_test <- cbind(algae_test_conc, algae_test_norm)
# 
# names(algae_train) <- make.names(names(algae_train))
# names(algae_test) <- make.names(names(algae_test))

```

```{r nn}
set.seed(55)
algae_model <- neuralnet(bluegreen_algae_conc_ug.L~., data=algae_train, hidden= c(10,6),err.fct = 'sse', act.fct = 'logistic')

plot(algae_model)


```


```{r model accuracy}
set.seed(55)
algae_pred <- compute(algae_model, algae_test[ , c(1:2, 4:length(algae_test))])
pred_results <- algae_pred$net.result
cor(pred_results, algae_test$bluegreen_algae_conc_ug.L)

algae_df <- data.frame(actual = algae_test$bluegreen_algae_conc_ug.L, predicted = pred_results)

```


```{r plotting}
set.seed(42)
plot_ly() %>%
  add_markers(x=pred_results, y=algae_test$bluegreen_algae_conc_ug.L, 
              name="Data Scatter", type="scatter", mode="markers") %>%
  add_trace(x = c(0,1), y = c(0,1), type="scatter", mode="lines",
        line = list(width = 4), name="Ideal Agreement") %>%
  layout(title=paste0('Scatterplot (Normalized) Observed vs. Predicted Values, Cor(Obs,Pred)=',
                      round(cor(pred_results, algae_test$bluegreen_algae_conc_.ug.L.), 2)),
           xaxis = list(title="NN (hidden=4) Predictions"),
           yaxis = list(title="(Normalized) Observed"),
           legend = list(orientation = 'h'))
```

```{r classifier}
set.seed(42)
algae_class <- algae_norm

headers <- c("chlorophyll_flourescence_(rfu)","oxygen_saturation_(fraction)","bluegreen_algae_conc_(ug/L)",
             "chlorophyll_conc_(kg/m3)","oxygen_conc_(kg/m3)","temp_(K)","elec_cond_(s/m)",
             "pH","nitrate_(ug/L)","ammonia_(ug/L)","phosphate_(ug/L)")
names(algae_class) <- headers

id1 = which(algae_class$`bluegreen_algae_conc_(ug/L)` < 0.1)
id2 = which(algae_class$`bluegreen_algae_conc_(ug/L)` > 0.2)
id3 = setdiff(1:nrow(algae_class),union(id1,id2))
algae_class$`bluegreen_algae_conc_(ug/L)`[id1]=0
algae_class$`bluegreen_algae_conc_(ug/L)`[id2]=2
algae_class$`bluegreen_algae_conc_(ug/L)`[id3]=1


summary(as.factor(algae_class$`bluegreen_algae_conc_(ug/L)`))


```

```{r classifier train and test}
set.seed(42)
train = sample(1:nrow(algae_class),0.75*nrow(algae_class))
algae_tr = algae_class[train,]
algae_ts = algae_class[-train,]
train_x = algae_tr[,c(1:2,4:11)]
train_y = algae_tr[,3]
colnames(train_x)

test_x = algae_ts[,c(1:2,4:8)]
test_y = algae_ts[3]
train_y_ind = model.matrix(~factor(train_y)-1)
colnames(train_y_ind) = c("Low","Median","High")
train = cbind(train_x, train_y_ind)
names(train) <- make.names(names(train))

```


```{r NN classifier}
set.seed(42)
nn_single = neuralnet(Low+Median+High~ .,
    data = train,
    hidden=10,#c(10,8,6),
    # linear.output=FALSE,
    # lifesign='full', lifesign.step=5000,
    threshold = 0.3)
```


```{r}
set.seed()
pred = function(nn, dat) {
    # compute uses the trained neural net (nn=nn_single), and 
    # new testing data (dat=google_ts) to generate predictions (y_hat)
    # compute returns a list containing: 
    #     (1) neurons: a list of the neurons' output for each layer of the neural network, and
    #     (2) net.result: a matrix containing the overall result of the neural network.
    yhat = compute(nn, dat)$net.result
    
    # find the maximum in each row (1) in the net.result matrix
    # to determine the first occurrence of a specific element in each row (1)
    # we can use the apply function with which.max
    yhat = apply(yhat, 1, which.max)-1
    return(yhat)
}

mean(pred(nn_single, algae_ts[,c(1:2,4:11)]) != as.factor(algae_ts[,3]))

table(pred(nn_single, algae_ts[,c(1:2,4:11)]), as.factor(algae_ts[,3]))

```

///////////////////////////////////////////////////////////////////////////////////

```{r deep learning}
set.seed(55)
## take a subset of the original data which does not include the predicted variable 
## Also take a subset of just the predicted variable
dl_all_input <- algae_sub %>% select(-c('bluegreen_algae_conc_ug.L','bluegreen_algae_conc_rfu'))
dl_all_output <- algae_sub %>% select(c('bluegreen_algae_conc_ug.L'))

## Function to normalize all the columns in the dataset
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}

## Normalizes both the input and output dataset
dl_norm_input <-as.data.frame(lapply(dl_all_input, normalize))
dl_norm_output <-as.data.frame(lapply(dl_all_output, normalize))

## Randomly samples the indexes to create training and testing data
sub <- sample(nrow(dl_norm_output), floor(nrow(dl_norm_output)*0.90))

## Index the input and ouput datasets with the randomly generated indexes to get training and testing inputs/outputs
dl_train_input <- dl_norm_input[sub, ] 
dl_train_output <- dl_norm_output[sub, ]
dl_test_input <- dl_norm_input[-sub, ]
dl_test_output <- dl_norm_output[-sub, ]

## Turn all training and testing data into matrices
dl_train_mat <- as.matrix(dl_train_input)
dl_test_mat <- as.matrix(dl_test_input)
dl_train_output <- as.matrix(dl_train_output)
dl_test_output <-as.matrix(dl_test_output)

## Remove column names
colnames(dl_train_mat) <- NULL
colnames(dl_test_mat) <- NULL
```


```{r model build}
dl_model <- keras_model_sequential() 
act <- 'relu'
opt <- 'Adam'
loss <- 'mse'
met <- 'mse'
# Add layers to the model
set.seed(55)
dl_model %>% 
    layer_dense(units = 10, activation = act, input_shape = length(dl_train_input)) %>% 
    layer_dense(units = 120, activation = act) %>%
    layer_dropout(rate = 0.3) %>% 
    layer_dense(units = 1, activation = 'linear')

dl_model %>% compile(
     loss = loss,
     optimizer = opt,
     metrics = met
 )
summary(dl_model)
history <- dl_model %>% fit(
  dl_train_mat,
  dl_train_output,
  validation_split = 0.2,
  verbose = 0,
  epochs = 200
)

plot(history)


test_results <- dl_model %>% evaluate(
  dl_test_mat,
  dl_test_output,
  verbose = 0
)
test_results


test_predictions <- predict(dl_model, dl_test_mat)

df <- data.frame(prediction = as.numeric(test_predictions), concentration = dl_test_output)

plot_ly() %>%
  add_markers(data=df, x=~prediction, y=~concentration, 
              name="Data Scatter", type="scatter", mode="markers") %>%
  add_trace(x = c(0,1), y = c(0,1), type="scatter", mode="lines",
        line = list(width = 4), name="Ideal Agreement") %>%
  layout(title=paste0('Scatterplot (Normalized) Observed vs. Predicted Values, Cor(Obs,Pred)=',
                      round(cor(df$prediction,df$concentration ), 2)),
           xaxis = list(title="NN (hidden=4) Predictions"),
           yaxis = list(title="(Normalized) Observed"),
           legend = list(orientation = 'h'))

cor(df$prediction, df$concentration)


```



```{r NN }

```
